{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8103705,"sourceType":"datasetVersion","datasetId":4785956}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom torch.utils.data import DataLoader,Dataset\nimport torch, torchtext\nfrom torchtext.functional import to_tensor\nfrom torchtext.models import (RobertaClassificationHead, \n                              ROBERTA_BASE_ENCODER, \n                              XLMR_LARGE_ENCODER)\nfrom sklearn.model_selection import train_test_split\n\nNUM_CLASSES = 11\n\ndevice = 'cuda' if torch.cuda.is_available else 'cpu'\ndevice","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-13T00:29:52.599456Z","iopub.execute_input":"2024-04-13T00:29:52.599982Z","iopub.status.idle":"2024-04-13T00:29:59.279942Z","shell.execute_reply.started":"2024-04-13T00:29:52.599950Z","shell.execute_reply":"2024-04-13T00:29:59.279070Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# !pip install torchtext","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:01.421184Z","iopub.execute_input":"2024-04-13T00:30:01.422068Z","iopub.status.idle":"2024-04-13T00:30:01.425856Z","shell.execute_reply.started":"2024-04-13T00:30:01.422037Z","shell.execute_reply":"2024-04-13T00:30:01.424915Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/textdata/sample.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:02.228960Z","iopub.execute_input":"2024-04-13T00:30:02.229339Z","iopub.status.idle":"2024-04-13T00:30:02.341346Z","shell.execute_reply.started":"2024-04-13T00:30:02.229312Z","shell.execute_reply":"2024-04-13T00:30:02.340450Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"           class                                               text\n0    arrangement  СОГЛАШЕНИЕ N 8\\nо расторжении трудового догово...\n1    arrangement  Соглашение о предоставлении опциона на заключе...\n2    arrangement  Соглашение\\nо реструктуризации задолженности\\n...\n3    arrangement  Дополнительное соглашение\\r\\nк договору купли-...\n4    arrangement  Соглашение\\nо расторжении договора об оказании...\n..           ...                                                ...\n496         bill  Счет № 5 от 01 октября 2020 г.\\r\\n\\r\\nПоставщи...\n497         bill  Счет на оплату № от 14 октября 2020 года\\r\\n\\r...\n498         bill  Счет №23                  от 12.09.2024 г.\\t\\t...\n499         bill  \"Огурец!\" (ИП Микрюков В.В.)\\t\\t\\t\\t\\t\\t\\r\\n\\t...\n500         bill  ООО «Тигр-Ряв»\\t\\t \\r\\nг. Липецк, ул. Масленая...\n\n[501 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>arrangement</td>\n      <td>СОГЛАШЕНИЕ N 8\\nо расторжении трудового догово...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arrangement</td>\n      <td>Соглашение о предоставлении опциона на заключе...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>arrangement</td>\n      <td>Соглашение\\nо реструктуризации задолженности\\n...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arrangement</td>\n      <td>Дополнительное соглашение\\r\\nк договору купли-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arrangement</td>\n      <td>Соглашение\\nо расторжении договора об оказании...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>bill</td>\n      <td>Счет № 5 от 01 октября 2020 г.\\r\\n\\r\\nПоставщи...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>bill</td>\n      <td>Счет на оплату № от 14 октября 2020 года\\r\\n\\r...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>bill</td>\n      <td>Счет №23                  от 12.09.2024 г.\\t\\t...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>bill</td>\n      <td>\"Огурец!\" (ИП Микрюков В.В.)\\t\\t\\t\\t\\t\\t\\r\\n\\t...</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>bill</td>\n      <td>ООО «Тигр-Ряв»\\t\\t \\r\\nг. Липецк, ул. Масленая...</td>\n    </tr>\n  </tbody>\n</table>\n<p>501 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"mapping = {'act': 0,\n         'application': 1,\n         'arrangement': 2,\n         'bill': 3,\n         'contract': 4,\n         'contract offer': 5,\n         'determination': 6,\n         'invoice': 7,\n         'order': 8,\n         'proxy': 9,\n         'statute': 10}\nunmapping = {v:k for k,v in mapping.items()}\nunmapping","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:02.883278Z","iopub.execute_input":"2024-04-13T00:30:02.884023Z","iopub.status.idle":"2024-04-13T00:30:02.891869Z","shell.execute_reply.started":"2024-04-13T00:30:02.883989Z","shell.execute_reply":"2024-04-13T00:30:02.890867Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{0: 'act',\n 1: 'application',\n 2: 'arrangement',\n 3: 'bill',\n 4: 'contract',\n 5: 'contract offer',\n 6: 'determination',\n 7: 'invoice',\n 8: 'order',\n 9: 'proxy',\n 10: 'statute'}"},"metadata":{}}]},{"cell_type":"code","source":"data['class'].map(mapping).value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:03.433819Z","iopub.execute_input":"2024-04-13T00:30:03.434657Z","iopub.status.idle":"2024-04-13T00:30:03.450981Z","shell.execute_reply.started":"2024-04-13T00:30:03.434626Z","shell.execute_reply":"2024-04-13T00:30:03.450082Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"class\n9     71\n4     70\n0     69\n1     61\n8     50\n7     43\n3     41\n2     40\n5     25\n10    21\n6     10\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"class DocDataset(torch.utils.data.Dataset):\n    # overload the key dunder methods\n    def __init__(self, df, num_rows=None):\n        self.dataset =  df\n        self.dataset['class'] = self.dataset['class'].map(mapping)\n        # numpy\n        self.x = self.dataset.values\n        self.x_tmp = self.x[:, 0]\n        # cannot convert to tensor - still text\n        self.y_tmp = self.x[:, 1]\n\n    def __getitem__(self, idx):\n        text = self.x_tmp[idx]\n        targ = self.y_tmp[idx]\n        # Return as a tuple with targ/label and then text.\n        # This matters later when implementing def collate_data(batch)\n        sample = (targ,text)\n        return sample\n            \n    def __len__(self):\n        return len(self.x_tmp)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:03.836273Z","iopub.execute_input":"2024-04-13T00:30:03.836609Z","iopub.status.idle":"2024-04-13T00:30:03.845066Z","shell.execute_reply.started":"2024-04-13T00:30:03.836583Z","shell.execute_reply":"2024-04-13T00:30:03.844177Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(data, test_size=0.15, \n                                    random_state=60, stratify=data['class'])\n\nBATCH_SIZE = 4\ntrain_dataset = DocDataset(train_df)\nvalid_dataset = DocDataset(val_df)\n\ntrain_loader = DataLoader(train_dataset, BATCH_SIZE, num_workers=4, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, BATCH_SIZE, num_workers=4, shuffle=False)\n\nprint(f\"Length of train: {len(train_dataset)}, length of valid: {len(valid_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:04.583549Z","iopub.execute_input":"2024-04-13T00:30:04.584394Z","iopub.status.idle":"2024-04-13T00:30:04.600232Z","shell.execute_reply.started":"2024-04-13T00:30:04.584361Z","shell.execute_reply":"2024-04-13T00:30:04.599275Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Length of train: 425, length of valid: 76\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier_head = RobertaClassificationHead(num_classes=NUM_CLASSES, input_dim=1024)\n\nxlmr = XLMR_LARGE_ENCODER\ntransformer = xlmr.transform()\ninput_batch = [\"Привет\", \"Hello\"]\nmodel_input = to_tensor(transformer(input_batch), padding_value=1).to(device)\nmodel = xlmr.get_model(head=classifier_head).to(device)\n\nwith torch.no_grad():\n    print(model_input, model_input.size())\n    print(model(model_input), model(model_input).size())","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:04.962181Z","iopub.execute_input":"2024-04-13T00:30:04.963120Z","iopub.status.idle":"2024-04-13T00:30:40.961826Z","shell.execute_reply.started":"2024-04-13T00:30:04.963085Z","shell.execute_reply":"2024-04-13T00:30:40.960642Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"100%|██████████| 5.07M/5.07M [00:00<00:00, 54.3MB/s]\nDownloading: \"https://download.pytorch.org/models/text/xlmr.vocab.pt\" to /root/.cache/torch/hub/checkpoints/xlmr.vocab.pt\n100%|██████████| 4.85M/4.85M [00:00<00:00, 66.7MB/s]\nDownloading: \"https://download.pytorch.org/models/text/xlmr.large.encoder.pt\" to /root/.cache/torch/hub/checkpoints/xlmr.large.encoder.pt\n100%|██████████| 2.08G/2.08G [00:28<00:00, 79.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"tensor([[    0,  1813, 18454,     2],\n        [    0, 35378,     2,     1]], device='cuda:0') torch.Size([2, 4])\ntensor([[ 0.4749,  0.2213, -0.1027, -0.0729, -0.1334, -0.0614, -0.0048,  0.3618,\n         -0.0352,  0.0778, -0.3171],\n        [ 0.3213,  0.0744, -0.1230, -0.1659, -0.3443, -0.0170,  0.2645,  0.2863,\n          0.0728,  0.1417, -0.1826]], device='cuda:0') torch.Size([2, 11])\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_epoch(transformer, loader, model, \n                loss_fn, optimizer, scheduler, device):\n    model = model.to(device)\n    model.train()\n    avg_loss = 0.\n    for text, target in loader:\n        optimizer.zero_grad()  # Обнуляем градиенты\n        x = text\n        y = target.to(device)\n        x = to_tensor(transformer(list(x)), padding_value=1).to(device)\n        \n        pred_cls = model(x)\n        # print(prediction_seg)\n        loss = loss_fn(pred_cls, y)\n        loss.backward()\n        optimizer.step()\n        avg_loss += loss.item()\n    avg_loss /= len(loader)\n    scheduler.step(avg_loss)  # Обновляем скорость обучения\n    return avg_loss\n\n\ndef valid_epoch(transformer, loader, model, device, score):\n    model = model.to(device)\n    model.eval()\n    scores = []\n    with torch.no_grad():\n        for text, target in loader:\n            x = text\n            y = target.to(device)\n            x = to_tensor(transformer(list(x)), padding_value=1).to(device)\n            \n            probs = torch.sigmoid(model(x)).to(device)\n            scores.append(score(probs, y))\n    return torch.stack(scores).mean().item()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:40.963639Z","iopub.execute_input":"2024-04-13T00:30:40.964621Z","iopub.status.idle":"2024-04-13T00:30:40.975738Z","shell.execute_reply.started":"2024-04-13T00:30:40.964587Z","shell.execute_reply":"2024-04-13T00:30:40.974879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:42.996433Z","iopub.execute_input":"2024-04-13T00:30:42.996775Z","iopub.status.idle":"2024-04-13T00:30:43.005623Z","shell.execute_reply.started":"2024-04-13T00:30:42.996750Z","shell.execute_reply":"2024-04-13T00:30:43.004601Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RobertaModel(\n  (encoder): RobertaEncoder(\n    (transformer): TransformerEncoder(\n      (token_embedding): Embedding(250002, 1024, padding_idx=1)\n      (layers): TransformerEncoder(\n        (layers): ModuleList(\n          (0-23): 24 x TransformerEncoderLayer(\n            (self_attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n            )\n            (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n            (dropout1): Dropout(p=0.1, inplace=False)\n            (dropout2): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (positional_embedding): PositionalEmbedding(\n        (embedding): Embedding(514, 1024, padding_idx=1)\n      )\n      (embedding_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (head): RobertaClassificationHead(\n    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=1024, out_features=11, bias=True)\n    (activation_fn): ReLU()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"mapping","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:43.880169Z","iopub.execute_input":"2024-04-13T00:30:43.880670Z","iopub.status.idle":"2024-04-13T00:30:45.927759Z","shell.execute_reply.started":"2024-04-13T00:30:43.880641Z","shell.execute_reply":"2024-04-13T00:30:45.926770Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'act': 0,\n 'application': 1,\n 'arrangement': 2,\n 'bill': 3,\n 'contract': 4,\n 'contract offer': 5,\n 'determination': 6,\n 'invoice': 7,\n 'order': 8,\n 'proxy': 9,\n 'statute': 10}"},"metadata":{}}]},{"cell_type":"code","source":"data['class'].value_counts().sort_index()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:46.515611Z","iopub.execute_input":"2024-04-13T00:30:46.515971Z","iopub.status.idle":"2024-04-13T00:30:46.526713Z","shell.execute_reply.started":"2024-04-13T00:30:46.515942Z","shell.execute_reply":"2024-04-13T00:30:46.525582Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"class\nact               69\napplication       61\narrangement       40\nbill              41\ncontract          70\ncontract offer    25\ndetermination     10\ninvoice           43\norder             50\nproxy             71\nstatute           21\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"target = data['class'].map(mapping)\nclass_sample_count = np.unique(target, return_counts=True)[1]\nweight = 1. / class_sample_count\nsamples_weight = weight[target]\nsamples_weight = torch.from_numpy(samples_weight)","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:47.521397Z","iopub.execute_input":"2024-04-13T00:30:47.521979Z","iopub.status.idle":"2024-04-13T00:30:48.102202Z","shell.execute_reply.started":"2024-04-13T00:30:47.521948Z","shell.execute_reply":"2024-04-13T00:30:48.100668Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.head.activation_fn = torch.nn.Softmax()","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:49.264109Z","iopub.execute_input":"2024-04-13T00:30:49.264935Z","iopub.status.idle":"2024-04-13T00:30:49.271169Z","shell.execute_reply.started":"2024-04-13T00:30:49.264878Z","shell.execute_reply":"2024-04-13T00:30:49.270267Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from torchmetrics import Accuracy\n\nlossfn = torch.nn.CrossEntropyLoss(weight=torch.from_numpy(weight.astype(np.float32)).to(device))\noptimizer = torch.optim.Adam(model.parameters(),  lr=1e-4)\nscheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, \n                                              end_factor=0.2, total_iters=30, \n                                              last_epoch=-1)\n\naccuracy = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES, top_k=1).to(device)\n\ntransformer = transformer\ntrain_loader, valid_loader\nscore = accuracy\nloss_fn = lossfn\noptimizer, scheduler, device\n\nbest_score = 0\n\nfor epoch in range(100):\n    train_loss = train_epoch(transformer=transformer,\n                             loader=train_loader, \n                             model=model, \n                             loss_fn=loss_fn, \n                             optimizer=optimizer, \n                             scheduler=scheduler, \n                             device=device)\n    valid_score = valid_epoch(transformer=transformer,\n                              loader=valid_loader, \n                              model=model, \n                              device=device,\n                              score=accuracy\n                             )\n    \n    if valid_score > best_score:\n        torch.save(model.state_dict(), 'best_model.pth')\n        best_score = valid_score\n        \n    print(f'Epoch: {epoch}, train_loss: {train_loss}, valid_score: {valid_score}\\n')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T00:30:50.503592Z","iopub.execute_input":"2024-04-13T00:30:50.503941Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:380: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, train_loss: 2.3978748900868068, valid_score: 0.09210526198148727\n\nEpoch: 1, train_loss: 2.39730208833641, valid_score: 0.09210526198148727\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}